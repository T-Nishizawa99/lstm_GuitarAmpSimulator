{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"modeling_LSTM.ipynb","provenance":[{"file_id":"1Xe9-VVEKckVKASMQWj7TeAzoq1OWlEOm","timestamp":1573905613915},{"file_id":"1pJFMXOO3SyeageRIr9pwLRwnlWNx5wpJ","timestamp":1570850300687}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZRCr4WEdWU0A","colab_type":"text"},"source":["このプログラムは「機械学習でギターアンプをモデリングする」\n","\n","（https://qiita.com/coz-a/items/aeab3c52e3f12ba52a8b）\n","\n","を基に作成しています．\n","\n","データ解像度16bit-48kHzと24bit-192kHzの切り替えは適宜変更してください．\n"]},{"cell_type":"markdown","metadata":{"id":"uF8Nf_6jZQC_","colab_type":"text"},"source":["データの読み書き，教師データの前処理，trainメソッド\n"]},{"cell_type":"code","metadata":{"id":"nttlYQQE72I6","colab_type":"code","colab":{}},"source":["import os\n","import datetime\n","import wave\n","import yaml\n","import numpy as np\n","import soundfile as sf\n","from numpy.lib.stride_tricks import as_strided\n","from keras.models import Sequential\n","from keras.layers import CuDNNLSTM, BatchNormalization\n","from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n","from keras.losses import mean_squared_error\n","\n","def load_wave(wave_file):\n","    wave,fs=sf.read(wave_file,dtype=np.float32)\n","    buf = wave.reshape(-1, )\n","    return buf\n","\n","# bufferの内容をwavfileにしてoutputする関数\n","def save_wave(buf, wave_file):\n","    _buf = buf.reshape(-1,2)\n","    sf.write(wave_file,_buf,samplerate=192000,subtype=\"PCM_24\")\n","\n","def flow(dataset, timesteps, batch_size):\n","    n_data = len(dataset)\n","    while True:\n","        i = np.random.randint(n_data)\n","        x, y = dataset[i]\n","        yield random_clop(x, y, timesteps, batch_size)\n","\n","def random_clop(x, y, timesteps, batch_size):\n","    max_offset = len(x) - timesteps\n","    offsets = np.random.randint(max_offset, size=batch_size)\n","    batch_x = np.stack((x[offset:offset+timesteps] for offset in offsets))\n","    batch_y = np.stack((y[offset:offset+timesteps] for offset in offsets))\n","    return batch_x, batch_y\n","\n","def build_model(timesteps):\n","    model = Sequential()\n","    model.add(CuDNNLSTM(64, input_shape=(timesteps, 1), return_sequences=True, name=\"lstm_1\"))\n","    model.add(CuDNNLSTM(64, return_sequences=True, name=\"lstm_2\"))\n","    model.add(CuDNNLSTM(1, return_sequences=True, name=\"lstm_out\"))\n","    return model\n","\n","class LossFunc:\n","\n","    def __init__(self, timesteps):\n","        self.__name__ = \"LossFunc\"\n","        self.timesteps = timesteps\n","    \n","    def __call__(self, y_true, y_pred):\n","        return mean_squared_error(\n","            y_true[:, -self.timesteps:, :],\n","            y_pred[:, -self.timesteps:, :])\n","\n","def train(model, train_dataflow, val_dataflow, max_epochs, patience):\n","    timestamp = datetime.datetime.now()\n","\n","    cp_dir = \"./checkpoint/model_24_192\"\n","    if not os.path.exists(cp_dir):\n","        os.makedirs(cp_dir)\n","    cp_filepath = os.path.join(cp_dir, \"model_{epoch:06d}.h5\")\n","    cb_mc = ModelCheckpoint(filepath=cp_filepath, monitor=\"val_loss\", period=1, save_best_only=True)\n","\n","    cb_es = EarlyStopping(monitor=\"val_loss\", patience=patience)\n","\n","    tb_log_dir = \"./tensorboard/model_24_192\"\n","    cb_tb = TensorBoard(log_dir=tb_log_dir)\n","    #モデルをある状態からロードしたい場合に以下を使用する\n","    #model.load_weights(os.path.join(\"./checkpoint/model_24_192\", \"model_000007.h5\"))\n","\n","    model.fit_generator(\n","        generator=train_dataflow,\n","        steps_per_epoch=100,\n","        validation_data=val_dataflow,\n","        validation_steps=10,\n","        epochs=max_epochs,\n","        callbacks=[cb_mc, cb_es, cb_tb])\n","\n","def sliding_window(x, window, slide):\n","    n_slide = (len(x) - window) // slide\n","    remain = (len(x) - window) % slide\n","    clopped = x[:-remain]\n","    return as_strided(clopped, shape=(n_slide + 1, window), strides=(slide * 4, 4))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LSiK2tU6ZUCt","colab_type":"text"},"source":["training\n"]},{"cell_type":"code","metadata":{"id":"HGGO7Hjw3Gm4","colab_type":"code","colab":{}},"source":["import yaml\n","\n","def main():\n","    \n","    \n","    with open(\"./config_24_192.yml\") as fp:\n","        config = yaml.safe_load(fp)\n","    \n","    input_timesteps = config[\"input_timesteps\"]\n","    output_timesteps = config[\"output_timesteps\"]\n","    batch_size = config[\"batch_size\"]\n","    max_epochs = config[\"max_epochs\"]\n","    patience = config[\"patience\"]\n","\n","    train_dataset = [\n","        (load_wave(_[0]).reshape(-1, 1), load_wave(_[1]).reshape(-1, 1))\n","        for _ in config[\"train_data\"]]\n","    train_dataflow = flow(train_dataset, input_timesteps, batch_size)\n","\n","    val_dataset = [\n","        (load_wave(_[0]).reshape(-1, 1), load_wave(_[1]).reshape(-1, 1))\n","        for _ in config[\"val_data\"]]\n","    val_dataflow = flow(val_dataset, input_timesteps, batch_size)\n","   \n","    model = build_model(input_timesteps)\n","    model.compile(\n","        loss=LossFunc(output_timesteps),\n","        optimizer=\"adam\")\n","    \n","    train(model, train_dataflow, val_dataflow, max_epochs, patience)\n","\n","if __name__ == '__main__':\n","    main()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1VILn4myZX0K","colab_type":"text"},"source":["predict"]},{"cell_type":"code","metadata":{"id":"ABWCqLAGE4-G","colab_type":"code","colab":{}},"source":["import numpy as np\n","import yaml\n","import soundfile as sf\n","from keras.models import load_model\n","\n","def main():\n","    \n","    with open(\"./config_24_192.yml\") as fp:\n","        config = yaml.safe_load(fp)\n","\n","    input_timesteps = config[\"input_timesteps\"]\n","    output_timesteps = config[\"output_timesteps\"]\n","    batch_size = config[\"batch_size\"]\n","\n","    data = load_wave(\"./data/recording/recording_input1_192.wav\")\n","\n","    # padding and rounded up to the batch multiple\n","    block_size = output_timesteps * batch_size\n","    prepad = input_timesteps - output_timesteps\n","    postpad = len(data) % block_size\n","    padded = np.concatenate((\n","        np.zeros(prepad, np.float32),\n","        data,\n","        np.zeros(postpad, np.float32)))\n","    x = sliding_window(padded, input_timesteps, output_timesteps)\n","    x = x[:, :, np.newaxis]\n","\n","    model = load_model(\n","        \"./checkpoint/model_24_192/model_000043.h5\",\n","        custom_objects={\"LossFunc\": LossFunc(output_timesteps)})\n","    \n","    y = model.predict(x, batch_size=batch_size)\n","    y = y[:, -output_timesteps:, :].reshape(-1)[:len(data)]\n","    save_wave(y, \"./data/recording/recording_predicted1_192.wav\")\n","\n","if __name__ == '__main__':\n","    main()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nOPb67-bTzM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}